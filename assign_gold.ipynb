{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import talib as ta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Load gold historical data from Yahoo Finance\n",
    "data = yf.download('^XAU', start='2019-01-01', end='2024-01-01') # โหลดข้อมูลมาแล้วระบุวันเริ่มกับวันสุดท้าย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Return'] = data['Close'].pct_change() # ทำค่าผลต่างเป็นเปอร์เซ็นจากวันปัจจุบันและวันก่อนหน้า return ก็คือผลตอบแทนที่ดได้จากราคาปิดวันนี้เทียบกับเมื่อวาน\n",
    "\n",
    "# Add more technical indicators\n",
    "# หา Simple Moving Average ช่วง 10 และ 50 วัน\n",
    "data['SMA_15'] = ta.SMA(data['Close'].to_numpy().flatten(), timeperiod=15)\n",
    "data['SMA_30'] = ta.SMA(data['Close'].to_numpy().flatten(), timeperiod=30)\n",
    "data['SMA_60'] = ta.SMA(data['Close'].to_numpy().flatten(), timeperiod=60)\n",
    "\n",
    "# หา Relative Strength Index ในช่วง 14 วัน\n",
    "# หาก RSI ต่ำกว่า 30% จะเรียกว่าภาวะ “ขายมากเกินไป” (Oversold)\n",
    "# หาก RSI สูงกว่า 70% จะเรียกว่าภาวะ “ซื้อมากเกินไป” (Overbought)\n",
    "data['RSI'] = ta.RSI(data['Close'].to_numpy().flatten(), timeperiod=14)\n",
    "\n",
    "# หา Moving Average Convergence Divergence ตัว MACD หาได้จากความต่างของ EMA (Exponential Moving Average) สองเส้นหรือ EMA12 - EMA26\n",
    "# เอาไว้ดูคู่กับ signal line เพื่อประกอบการตัดสินใจจังหวะซื้อหรือขาย\n",
    "data['MACD'], data['MACD_Signal'], _ = ta.MACD(data['Close'].to_numpy().flatten(), fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "\n",
    "# Bollinger Bands กรอบราคาที่สามารเหวี่ยงไปได้ทั้งกรอบบน กรอบล่าง\n",
    "data['BB_upper'], data['BB_middle'], data['BB_lower'] = ta.BBANDS(data['Close'].to_numpy().flatten(), timeperiod=20)\n",
    "\n",
    "# หา momentum ซึ่งเป็นอัตราเร่งของราคา\n",
    "data['Momentum'] = ta.MOM(data['Close'].to_numpy().flatten(), timeperiod=10)\n",
    "\n",
    "# หาความผันผวนของราคาปิดเมื่อเทียบกับราคาสูงสุดและต่ำสุด\n",
    "data['Volatility'] = ta.ATR(data['High'].to_numpy().flatten(), data['Low'].to_numpy().flatten(), data['Close'].to_numpy().flatten(), timeperiod=14)  # Added Volatility\n",
    "\n",
    "# หาค่า Stochastic ออกมาเป็นเปอร์เซ็นเพื่อดูพฤติกรรมการซื้อขาย เพื่อหาจุดที่จะเก็งกำไร ส่วนใหญ่ทำในระยะสั้น\n",
    "data['Stochastic'] = ta.STOCH(data['High'].to_numpy().flatten(), data['Low'].to_numpy().flatten(), data['Close'].to_numpy().flatten(), fastk_period=14, slowk_period=3)[0]  # Added Stochastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>SMA_15</th>\n",
       "      <th>SMA_30</th>\n",
       "      <th>SMA_60</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>BB_upper</th>\n",
       "      <th>BB_middle</th>\n",
       "      <th>BB_lower</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Stochastic</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>^XAU</th>\n",
       "      <th>^XAU</th>\n",
       "      <th>^XAU</th>\n",
       "      <th>^XAU</th>\n",
       "      <th>^XAU</th>\n",
       "      <th>^XAU</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02 00:00:00+00:00</th>\n",
       "      <td>70.940002</td>\n",
       "      <td>70.940002</td>\n",
       "      <td>71.790001</td>\n",
       "      <td>69.860001</td>\n",
       "      <td>70.440002</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03 00:00:00+00:00</th>\n",
       "      <td>72.169998</td>\n",
       "      <td>72.169998</td>\n",
       "      <td>72.389999</td>\n",
       "      <td>70.860001</td>\n",
       "      <td>71.470001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04 00:00:00+00:00</th>\n",
       "      <td>71.870003</td>\n",
       "      <td>71.870003</td>\n",
       "      <td>72.230003</td>\n",
       "      <td>70.570000</td>\n",
       "      <td>71.419998</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07 00:00:00+00:00</th>\n",
       "      <td>71.199997</td>\n",
       "      <td>71.199997</td>\n",
       "      <td>72.459999</td>\n",
       "      <td>70.980003</td>\n",
       "      <td>72.339996</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08 00:00:00+00:00</th>\n",
       "      <td>71.470001</td>\n",
       "      <td>71.470001</td>\n",
       "      <td>71.669998</td>\n",
       "      <td>70.230003</td>\n",
       "      <td>70.769997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                      Adj Close      Close       High        Low  \\\n",
       "Ticker                          ^XAU       ^XAU       ^XAU       ^XAU   \n",
       "Date                                                                    \n",
       "2019-01-02 00:00:00+00:00  70.940002  70.940002  71.790001  69.860001   \n",
       "2019-01-03 00:00:00+00:00  72.169998  72.169998  72.389999  70.860001   \n",
       "2019-01-04 00:00:00+00:00  71.870003  71.870003  72.230003  70.570000   \n",
       "2019-01-07 00:00:00+00:00  71.199997  71.199997  72.459999  70.980003   \n",
       "2019-01-08 00:00:00+00:00  71.470001  71.470001  71.669998  70.230003   \n",
       "\n",
       "Price                           Open Volume    Return SMA_15 SMA_30 SMA_60  \\\n",
       "Ticker                          ^XAU   ^XAU                                  \n",
       "Date                                                                         \n",
       "2019-01-02 00:00:00+00:00  70.440002      0       NaN    NaN    NaN    NaN   \n",
       "2019-01-03 00:00:00+00:00  71.470001      0  0.017339    NaN    NaN    NaN   \n",
       "2019-01-04 00:00:00+00:00  71.419998      0 -0.004157    NaN    NaN    NaN   \n",
       "2019-01-07 00:00:00+00:00  72.339996      0 -0.009322    NaN    NaN    NaN   \n",
       "2019-01-08 00:00:00+00:00  70.769997      0  0.003792    NaN    NaN    NaN   \n",
       "\n",
       "Price                     RSI MACD MACD_Signal BB_upper BB_middle BB_lower  \\\n",
       "Ticker                                                                       \n",
       "Date                                                                         \n",
       "2019-01-02 00:00:00+00:00 NaN  NaN         NaN      NaN       NaN      NaN   \n",
       "2019-01-03 00:00:00+00:00 NaN  NaN         NaN      NaN       NaN      NaN   \n",
       "2019-01-04 00:00:00+00:00 NaN  NaN         NaN      NaN       NaN      NaN   \n",
       "2019-01-07 00:00:00+00:00 NaN  NaN         NaN      NaN       NaN      NaN   \n",
       "2019-01-08 00:00:00+00:00 NaN  NaN         NaN      NaN       NaN      NaN   \n",
       "\n",
       "Price                     Momentum Volatility Stochastic Target  \n",
       "Ticker                                                           \n",
       "Date                                                             \n",
       "2019-01-02 00:00:00+00:00      NaN        NaN        NaN      1  \n",
       "2019-01-03 00:00:00+00:00      NaN        NaN        NaN      0  \n",
       "2019-01-04 00:00:00+00:00      NaN        NaN        NaN      0  \n",
       "2019-01-07 00:00:00+00:00      NaN        NaN        NaN      1  \n",
       "2019-01-08 00:00:00+00:00      NaN        NaN        NaN      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ทำ label เป็น buy, sell\n",
    "data['Target'] = np.where(data['Return'].shift(-1) > 0, 1, 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values after adding new features\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "def split_data(data, data_range, train_ratio=0.8):\n",
    "    split_range = int(len(data) * train_ratio)\n",
    "\n",
    "    features = [\n",
    "        'Return', 'SMA_15', 'SMA_30', 'SMA_60', 'RSI', 'MACD', 'MACD_Signal',\n",
    "        'BB_upper', 'BB_middle', 'BB_lower', 'Momentum', 'Volatility', 'Stochastic'\n",
    "    ]\n",
    "\n",
    "    pre_x_train = data.iloc[:split_range].loc[:,features]\n",
    "    pre_y_train = data.iloc[:split_range].loc[:,[\"Target\"]]\n",
    "    pre_x_test = data.iloc[split_range:].loc[:,features]\n",
    "    pre_y_test = data.iloc[split_range:].loc[:,[\"Target\"]]\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for i in range(len(pre_x_train)-data_range):\n",
    "        # x_tmp = np.transpose(pre_x_train.iloc[i:i+data_range].to_numpy())\n",
    "        x_tmp = pre_x_train.iloc[i:i+data_range].to_numpy()\n",
    "        y_tmp = pre_y_train.iloc[i+data_range-1].to_numpy()\n",
    "        x_train.append(x_tmp)\n",
    "        y_train.append(y_tmp)\n",
    "\n",
    "    for i in range(len(pre_x_test)-data_range):\n",
    "        # x_tmp = np.transpose(pre_x_test.iloc[i:i+data_range].to_numpy())\n",
    "        x_tmp = pre_x_test.iloc[i:i+data_range].to_numpy()\n",
    "        y_tmp = pre_y_test.iloc[i+data_range-1].to_numpy()\n",
    "        x_test.append(x_tmp)\n",
    "        y_test.append(y_tmp)\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(929, 30, 13) (929, 1) (210, 30, 13) (210, 1)\n",
      "(929, 28, 16)\n",
      "(929, 10, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\co_op\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = split_data(data, data_range=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\co_op\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def create_cnn1d_gru_model(input_shape, gru_units=64):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # CNN Layers (Convolutional Layer + MaxPooling)\n",
    "    model.add(layers.Conv1D(32, 3, activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "    \n",
    "    # model.add(layers.Conv1D(64, 3, activation='relu'))\n",
    "    # model.add(layers.MaxPooling1D(2))\n",
    "    \n",
    "    # model.add(layers.Conv1D(128, 3, activation='relu'))\n",
    "    # model.add(layers.MaxPooling1D(2))\n",
    "    \n",
    "    # Flatten the output from CNN layers to be input to GRU\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # GRU Layer\n",
    "    model.add(layers.Reshape((-1, 32)))  # Reshape for GRU, where -1 is sequence length, 128 is feature dimension\n",
    "    model.add(layers.GRU(gru_units, return_sequences=False))  # GRU Layer\n",
    "    \n",
    "    # Fully Connected Layer (Dense Layer)\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(2, activation='softmax'))  # Output layer (10 classes, change as needed)\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss=losses.SparseCategoricalCrossentropy())\n",
    "    \n",
    "    return model\n",
    "\n",
    "my_model = create_cnn1d_gru_model(x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6866\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6883\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6868\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6863\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6853\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6823\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6838\n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6843\n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6821\n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6869746446609497,\n",
       "  0.6866706013679504,\n",
       "  0.6863816976547241,\n",
       "  0.6857356429100037,\n",
       "  0.6856086254119873,\n",
       "  0.685441255569458,\n",
       "  0.6853477358818054,\n",
       "  0.6848428845405579,\n",
       "  0.683872401714325,\n",
       "  0.6840329170227051]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my_model.summary()\n",
    "history = my_model.fit(x_train, y_train, batch_size=100, epochs=10)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt ชุด 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import backtrader as bt # อันนี้น่าสนใจในการทำ backtest\n",
    "\n",
    "# Step 1: ดึงข้อมูลจาก Yahoo Finance\n",
    "data = yf.download('BTC-USD', start='2023-11-20', end='2024-11-20', progress=False)\n",
    "\n",
    "# Step 2: สร้าง Feature สำหรับ Machine Learning\n",
    "data['price_roc'] = data['Close'].pct_change() * 100  # Rate of Change ของราคา\n",
    "data['volume_roc'] = data['Volume'].pct_change() * 100  # Rate of Change ของ volume\n",
    "data = data.dropna()  # ลบค่า NaN ที่เกิดจากการคำนวณ\n",
    "\n",
    "# Step 3: กำหนด Target (1 = long, -1 = short)\n",
    "data['target'] = 0\n",
    "data.loc[data['price_roc'] > 0, 'target'] = 1  # long หากราคาเพิ่มขึ้น\n",
    "data.loc[data['price_roc'] < 0, 'target'] = -1  # short หากราคาลดลง\n",
    "\n",
    "# Step 4: การเตรียมข้อมูลสำหรับการฝึก Machine Learning\n",
    "X = data[['price_roc', 'volume_roc']]  # Features\n",
    "y = data['target']  # Target\n",
    "\n",
    "# แบ่งข้อมูลเป็น train/test (70% training, 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "# สร้างและฝึกโมเดล Machine Learning\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ทำนายผลใน test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# แสดงผลการทำนาย\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 5: สร้าง Strategy สำหรับ Backtrader\n",
    "class MLStrategy(bt.Strategy):\n",
    "    # กำหนดค่า parameter สำหรับการเข้าสู่ตลาด\n",
    "    def __init__(self):\n",
    "        self.model = model\n",
    "        self.data_close = self.datas[0].close\n",
    "        self.data_volume = self.datas[0].volume\n",
    "        self.X = pd.DataFrame({\n",
    "            'price_roc': self.data_close.pct_change() * 100,\n",
    "            'volume_roc': self.data_volume.pct_change() * 100\n",
    "        })\n",
    "        self.X = self.X.fillna(0)  # แทนที่ NaN ด้วย 0 เพื่อให้ไม่เกิดข้อผิดพลาดในการทำนาย\n",
    "        self.y_pred = self.model.predict(self.X.values)  # ทำนายคำสั่ง Long/Short\n",
    "    \n",
    "    def next(self):\n",
    "        if self.y_pred[-1] == 1:  # หากทำนาย long\n",
    "            if not self.position:  # ถ้ายังไม่ได้เปิด position\n",
    "                self.buy()\n",
    "        elif self.y_pred[-1] == -1:  # หากทำนาย short\n",
    "            if not self.position:  # ถ้ายังไม่ได้เปิด position\n",
    "                self.sell()\n",
    "\n",
    "# Step 6: การทำ Backtest โดยใช้ Backtrader\n",
    "cerebro = bt.Cerebro()\n",
    "\n",
    "# แปลงข้อมูลเป็น backtrader feed\n",
    "data_bt = bt.feeds.PandasData(dataname=data)\n",
    "\n",
    "# เพิ่มข้อมูลลงใน cerebro\n",
    "cerebro.adddata(data_bt)\n",
    "\n",
    "# เพิ่ม strategy ที่สร้างขึ้น\n",
    "cerebro.addstrategy(MLStrategy)\n",
    "\n",
    "# ตั้งค่าขนาดการลงทุนเริ่มต้น\n",
    "cerebro.broker.set_cash(10000)\n",
    "\n",
    "# ตั้งค่าค่าคอมมิชชั่น (เช่น 0.1% ต่อการเทรด)\n",
    "cerebro.broker.set_commission(commission=0.001)\n",
    "\n",
    "# รัน backtest\n",
    "cerebro.run()\n",
    "\n",
    "# แสดงกราฟผลลัพธ์\n",
    "cerebro.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt ชุด 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# ตัวอย่างการสร้างโมเดล CNN + GRU\n",
    "\n",
    "# สร้างโมเดล CNN + GRU\n",
    "def create_cnn_gru_model(input_shape, gru_units=64):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # CNN Layers (Convolutional Layer + MaxPooling)\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Flatten the output from CNN layers to be input to GRU\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # GRU Layer\n",
    "    model.add(layers.Reshape((-1, 128)))  # Reshape for GRU, where -1 is sequence length, 128 is feature dimension\n",
    "    model.add(layers.GRU(gru_units, return_sequences=False))  # GRU Layer\n",
    "    \n",
    "    # Fully Connected Layer (Dense Layer)\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))  # Output layer (10 classes, change as needed)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# สร้างโมเดล CNN + GRU\n",
    "input_shape = (64, 64, 3)  # ขนาดของภาพ (64x64 พิกเซล, 3 แชนแนล RGB)\n",
    "model = create_cnn_gru_model(input_shape)\n",
    "\n",
    "# คอมไพล์โมเดล\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# แสดงสรุปของโมเดล\n",
    "model.summary()\n",
    "\n",
    "# ตัวอย่างการฝึกโมเดล\n",
    "# สมมุติว่าเรามีข้อมูล train_X และ train_Y เป็นข้อมูลที่ประกอบด้วยลำดับของภาพ\n",
    "train_X = np.random.rand(100, 10, 64, 64, 3)  # 100 ตัวอย่าง, 10 ภาพในแต่ละลำดับ\n",
    "train_Y = np.random.randint(0, 10, (100,))  # 100 ป้ายกำกับ (10 คลาส)\n",
    "\n",
    "# การฝึกโมเดล\n",
    "model.fit(train_X, train_Y, epochs=10, batch_size=16)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
